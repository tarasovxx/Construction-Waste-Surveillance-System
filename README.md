# Система контроля за строительными отходами от команды Users

Мы, команда Users, разработали систему искусственного интеллекта, которая с помощью видеокамеры в режиме реального времени отслеживает подъезжающий самосвал и точно определяет к какому классу относится содержимое кузова. Взаимодействие с платформой осуществялется через удобный веб-сервис, который позволяет отслеживать работу в реальном времени и предоставляет вероятностным анализом содержимого кузова самосвала.


Мы используем современный подход детекции движения, чтобы точно сегментировать содержимое кузова подъехавшего самосвала на изображении и исключить влияние помех окружающего пространства, а после классифицируем класс объекта сверточной предобученной нейросетью.


Уникальность нашего решения заключается в его быстроте: оно способно лишь на одной CPU работать в режиме большой нагрузки и обрабатывать до 20 запросов в минуту, что позволяет Депстрою использовать его на практике.

Технические особенности:
Использование мультиязычного BERT для создания векторных представлений текста
Многоуровневая кластеризация: UMAP -> HDBSCAN -> CountVectorizer -> TF-IDF
- Эмоциональная окраска текста с помощью XLM Roberta, обученного на комментариях пользователей 
- Интерфейс на основе Streamlit


# Пример решения
![demo](https://github.com/Baltsat/users-rosatom/blob/main/data/gf.gif)

# Установка
- `git clone https://github.com/tarasovxx/Construction-Waste-Surveillance-System`
Необходим Python версии 3.9 и выше.
`pip install -r requirements.txt`
# Запуск
```bash
streamlit run app.py
```

# Используемое решение

* Для исходных данных проводится предобработка ответов: удаление пунктуации, фильтрация ненормативной лексики, лемматизация.
* На обработанных данных файнтюнены модели глубокого обучения, в частности, TweetNLP, XLM ROBERTA SENTIMENT MULTILINGUAL CLASSIFICATION, BertTopic.


* Визуализация кластеризации происходит посредством Streamlit. 

# Уникальность:

Наше уникальное решение объединяет передовой подход к обработке текста с помощью модели Bert, визуализацию результатов через интерфейс Streamlit и способность обрабатывать особенности русского и английского языка, что обеспечивает точность и простоту использования в сервисе "Мой Голос".

# Стек используемых технологий:

`Python3`, `git`, `GitHub` - инструменты разработки

`HF Transformers`, `TweetNLP`, `BertTopic` - библиотеки глубокого обучения

`Scikit-Learn`, `UMAP`, `KMeans` - фреймворки машинного обучения  

`Plotly`, `Streamlit`, `AltChart` - инструменты визуализации  


# Сравнение моделей

| Model  Description                                                | F1 Macro | Time    |
|--------------------------------------------------------|----------|---------|
| NaiveModel         каждое слово = новый кластер                                     | 0.81     | 10 ms   |
| LevensteinSimilarityModel    Если ответы схожие более, чем на 63% = образуют один кластер                          | 0.87     | 102 ms  |
| LevenshteinSimilatity + Processing Lemmatization, delete punct | 0.89     | 1 s     |
| SelfClusterModel#1 + SentimentTransformer (Bert-Multilingual + PCA + KMeans ) + (TweetNLP + xlm-roberta-multilingual) | 0.92     |         |
| SelfClusterModel#2                                     | 0.94     | 6 s     |
| SelfClusterModel#2 + SentimentTransformer              | 0.97     |         |







# Проводимые исследования

- `research_models_visualization.ipynb` - исследования с моделями градиентного бустинга
- `data_preprocess.ipynb` - предобработка данных 

# Документация Django API

Этот проект использует Django и Django Rest Framework для создания API. API предоставляет доступ к информации о вопросах и ответах (QA) и содержит следующие эндпойнты:

### Эндпойнт `/api/qaitems` Этот эндпойнт предоставляет доступ к данным о вопросах и ответах (QA). Он поддерживает следующие методы

-  `GET`: Получение списка всех элементов QA.

- `POST`: Создание нового элемента QA.

### Структура данных

Структура базы данных включает в себя следующие поля
- `question`: Текст вопроса.
- `answer`: Текст ответа.
- `sentiment`: Сентимент элемента.
- `j`: Значение J.
- `cluster_id`: Идентификатор кластера.
- `topic_name`: Название темы.

### Установка и запуск

Чтобы установить и запустить проект, выполните следующие шаги:
1. Клонируйте репозиторий с помощью `git clone`.
2. Создайте и активируйте виртуальное окружение.
3. Установите зависимости, выполнив команду `pip install -r requirements.txt`.
4. Примените миграции базы данных с помощью `python manage.py migrate`.
5. Запустите сервер с помощью `python manage.py runserver`.

## Примеры использования

Примеры запросов к API:
- Получение всех элементов QA: 
http://localhost:8000/api/qaitems/


# Разработчики
| Имя                  | Роль           | Контакт               |
|----------------------|----------------|-----------------------|
| Константин Балцат    | Data Analyse | [t.me/baltsat](https://t.me/baltsat)       |
| ---                  | ---            | ---                   |
| Александр Серов      | Machine Learning | [t.me/thegoldian](https://t.me/thegoldian) |
| ---                  | ---            | ---                   |
| Артем Тарасов        | Full stack | [t.me/tarasovxx](https://t.me/tarasovxx)   |
| ---                  | ---            | ---                   |
| Ванданов Сергей      | Machine Learning | [t.me/rapid76](https://t.me/@rapid76)      |
| ---                  | ---            | ---                   |
| Даниил Галимов       | Data Analyse | [t.me/Dan_Gan](https://t.me/Dan_Gan)  |
| ---                  | ---            | ---                   |



